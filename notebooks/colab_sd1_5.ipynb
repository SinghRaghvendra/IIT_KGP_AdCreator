{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dcf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ead7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Raghav/Documents/Project Haai/adcreatorapp/IIT_KGP_AdCreator/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install diffusers transformers accelerate safetensors gradio rembg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f356b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# Load the model (v1.5 example)\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,   # faster inference on GPU\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "# Move pipeline to GPU\n",
    "pipe = pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65001884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def generate_ad(prompt, out_dir=\"/content/drive/MyDrive/ad_outputs/\", n=1, steps=20):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    paths = []\n",
    "    for i in range(n):\n",
    "        out = pipe(prompt, num_inference_steps=steps, guidance_scale=7.5)\n",
    "        img = out.images[0]\n",
    "        path = os.path.join(out_dir, f\"ad_{i}.png\")\n",
    "        img.save(path)\n",
    "        paths.append(path)\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Modern banner ad for a smartwatch sale, clean layout, white background, product focus\"\n",
    "files = generate_ad(prompt, n=3, steps=25)\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio\n",
    "import gradio as gr\n",
    "\n",
    "def gradio_generate(prompt):\n",
    "    files = generate_ad(prompt, n=1)\n",
    "    return files[0]\n",
    "\n",
    "gr.Interface(fn=gradio_generate, inputs=\"text\", outputs=\"image\").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
